{"cells":[{"cell_type":"markdown","metadata":{"id":"ldeiV8Rsjtcs"},"source":["# Linear Discriminant Analysis"]},{"cell_type":"markdown","metadata":{"id":"gYFhHC31duWB"},"source":["### Objective\n","\n","Training a Linear Discriminant Analysis(LDA) model to check if the product has been shipped or canceled.\n","\n","### Problem Statement\n","\n","XYZ.com is an e-commerce company based in Argentina. Due to the covid crisis and lockdown XYZ.com is facing lots of issues from the dealer and the shipment team.  XYZ.com has lots of product data where various shipping and sales details of each product have been mentioned. XYZ.com wants to find out which of the products has been shipped and which of the products has been canceled to reduce customer escalation. As a data-scientist, We have to train an LDA(Linear Discriminant Analysis) model to predict which of the product has been shipped and which of the product has been canceled."]},{"cell_type":"markdown","metadata":{"id":"ONVPFqgsL8ry"},"source":["### 1. Import necessary libraries."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2kFsfPZXL8sC"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2VTgMsfTL8sE"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report,confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.preprocessing import StandardScaler,MinMaxScaler\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"]},{"cell_type":"markdown","metadata":{"id":"QaMn72C6L8sG"},"source":["### 2. Display a sample of five rows of the data frame"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bccGMqGYL8sH"},"outputs":[],"source":["df = pd.read_csv('sales_data_sample.csv',encoding='unicode_escape')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7HMBmKmtL8sI","outputId":"34463398-7729-482d-833a-fb96def59705"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ORDERNUMBER</th>\n","      <th>QUANTITYORDERED</th>\n","      <th>PRICEEACH</th>\n","      <th>ORDERLINENUMBER</th>\n","      <th>SALES</th>\n","      <th>ORDERDATE</th>\n","      <th>STATUS</th>\n","      <th>QTR_ID</th>\n","      <th>MONTH_ID</th>\n","      <th>YEAR_ID</th>\n","      <th>...</th>\n","      <th>ADDRESSLINE1</th>\n","      <th>ADDRESSLINE2</th>\n","      <th>CITY</th>\n","      <th>STATE</th>\n","      <th>POSTALCODE</th>\n","      <th>COUNTRY</th>\n","      <th>TERRITORY</th>\n","      <th>CONTACTLASTNAME</th>\n","      <th>CONTACTFIRSTNAME</th>\n","      <th>DEALSIZE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2173</th>\n","      <td>10107</td>\n","      <td>20</td>\n","      <td>92.90</td>\n","      <td>8</td>\n","      <td>1858.00</td>\n","      <td>2/24/2003 0:00</td>\n","      <td>Shipped</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2003</td>\n","      <td>...</td>\n","      <td>897 Long Airport Avenue</td>\n","      <td>NaN</td>\n","      <td>NYC</td>\n","      <td>NY</td>\n","      <td>10022</td>\n","      <td>USA</td>\n","      <td>NaN</td>\n","      <td>Yu</td>\n","      <td>Kwai</td>\n","      <td>Small</td>\n","    </tr>\n","    <tr>\n","      <th>1661</th>\n","      <td>10334</td>\n","      <td>42</td>\n","      <td>100.00</td>\n","      <td>5</td>\n","      <td>5528.04</td>\n","      <td>11/19/2004 0:00</td>\n","      <td>On Hold</td>\n","      <td>4</td>\n","      <td>11</td>\n","      <td>2004</td>\n","      <td>...</td>\n","      <td>Berguvsvgen  8</td>\n","      <td>NaN</td>\n","      <td>Lule</td>\n","      <td>NaN</td>\n","      <td>S-958 22</td>\n","      <td>Sweden</td>\n","      <td>EMEA</td>\n","      <td>Berglund</td>\n","      <td>Christina</td>\n","      <td>Medium</td>\n","    </tr>\n","    <tr>\n","      <th>614</th>\n","      <td>10278</td>\n","      <td>29</td>\n","      <td>90.86</td>\n","      <td>10</td>\n","      <td>2634.94</td>\n","      <td>8/6/2004 0:00</td>\n","      <td>Shipped</td>\n","      <td>3</td>\n","      <td>8</td>\n","      <td>2004</td>\n","      <td>...</td>\n","      <td>8489 Strong St.</td>\n","      <td>NaN</td>\n","      <td>Las Vegas</td>\n","      <td>NV</td>\n","      <td>83030</td>\n","      <td>USA</td>\n","      <td>NaN</td>\n","      <td>King</td>\n","      <td>Sue</td>\n","      <td>Small</td>\n","    </tr>\n","    <tr>\n","      <th>956</th>\n","      <td>10373</td>\n","      <td>22</td>\n","      <td>86.74</td>\n","      <td>5</td>\n","      <td>1908.28</td>\n","      <td>1/31/2005 0:00</td>\n","      <td>Shipped</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2005</td>\n","      <td>...</td>\n","      <td>Torikatu 38</td>\n","      <td>NaN</td>\n","      <td>Oulu</td>\n","      <td>NaN</td>\n","      <td>90110</td>\n","      <td>Finland</td>\n","      <td>EMEA</td>\n","      <td>Koskitalo</td>\n","      <td>Pirkko</td>\n","      <td>Small</td>\n","    </tr>\n","    <tr>\n","      <th>1598</th>\n","      <td>10197</td>\n","      <td>41</td>\n","      <td>100.00</td>\n","      <td>13</td>\n","      <td>4534.60</td>\n","      <td>11/26/2003 0:00</td>\n","      <td>Shipped</td>\n","      <td>4</td>\n","      <td>11</td>\n","      <td>2003</td>\n","      <td>...</td>\n","      <td>Rambla de Catalu¤a, 23</td>\n","      <td>NaN</td>\n","      <td>Barcelona</td>\n","      <td>NaN</td>\n","      <td>8022</td>\n","      <td>Spain</td>\n","      <td>EMEA</td>\n","      <td>Saavedra</td>\n","      <td>Eduardo</td>\n","      <td>Medium</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 25 columns</p>\n","</div>"],"text/plain":["      ORDERNUMBER  QUANTITYORDERED  PRICEEACH  ORDERLINENUMBER    SALES  \\\n","2173        10107               20      92.90                8  1858.00   \n","1661        10334               42     100.00                5  5528.04   \n","614         10278               29      90.86               10  2634.94   \n","956         10373               22      86.74                5  1908.28   \n","1598        10197               41     100.00               13  4534.60   \n","\n","            ORDERDATE   STATUS  QTR_ID  MONTH_ID  YEAR_ID  ...  \\\n","2173   2/24/2003 0:00  Shipped       1         2     2003  ...   \n","1661  11/19/2004 0:00  On Hold       4        11     2004  ...   \n","614     8/6/2004 0:00  Shipped       3         8     2004  ...   \n","956    1/31/2005 0:00  Shipped       1         1     2005  ...   \n","1598  11/26/2003 0:00  Shipped       4        11     2003  ...   \n","\n","                 ADDRESSLINE1  ADDRESSLINE2       CITY STATE POSTALCODE  \\\n","2173  897 Long Airport Avenue           NaN        NYC    NY      10022   \n","1661          Berguvsvgen  8           NaN       Lule   NaN   S-958 22   \n","614           8489 Strong St.           NaN  Las Vegas    NV      83030   \n","956               Torikatu 38           NaN       Oulu   NaN      90110   \n","1598   Rambla de Catalu¤a, 23           NaN  Barcelona   NaN       8022   \n","\n","      COUNTRY TERRITORY CONTACTLASTNAME CONTACTFIRSTNAME DEALSIZE  \n","2173      USA       NaN              Yu             Kwai    Small  \n","1661   Sweden      EMEA        Berglund        Christina   Medium  \n","614       USA       NaN            King              Sue    Small  \n","956   Finland      EMEA       Koskitalo           Pirkko    Small  \n","1598    Spain      EMEA        Saavedra          Eduardo   Medium  \n","\n","[5 rows x 25 columns]"]},"execution_count":92,"metadata":{},"output_type":"execute_result"}],"source":["df.sample(n=5)"]},{"cell_type":"markdown","metadata":{"id":"IDdvMs2rL8sK"},"source":["### 3. Check the shape of the data (number of rows and column). Check the general information about the dataframe using .info() method."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TqL0V1pSL8sL","outputId":"ee063271-ba1c-4d29-f958-c09d1aa110cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of the dataset (2823, 25)\n","******************************\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 2823 entries, 0 to 2822\n","Data columns (total 25 columns):\n"," #   Column            Non-Null Count  Dtype  \n","---  ------            --------------  -----  \n"," 0   ORDERNUMBER       2823 non-null   int64  \n"," 1   QUANTITYORDERED   2823 non-null   int64  \n"," 2   PRICEEACH         2823 non-null   float64\n"," 3   ORDERLINENUMBER   2823 non-null   int64  \n"," 4   SALES             2823 non-null   float64\n"," 5   ORDERDATE         2823 non-null   object \n"," 6   STATUS            2823 non-null   object \n"," 7   QTR_ID            2823 non-null   int64  \n"," 8   MONTH_ID          2823 non-null   int64  \n"," 9   YEAR_ID           2823 non-null   int64  \n"," 10  PRODUCTLINE       2823 non-null   object \n"," 11  MSRP              2823 non-null   int64  \n"," 12  PRODUCTCODE       2823 non-null   object \n"," 13  CUSTOMERNAME      2823 non-null   object \n"," 14  PHONE             2823 non-null   object \n"," 15  ADDRESSLINE1      2823 non-null   object \n"," 16  ADDRESSLINE2      302 non-null    object \n"," 17  CITY              2823 non-null   object \n"," 18  STATE             1337 non-null   object \n"," 19  POSTALCODE        2747 non-null   object \n"," 20  COUNTRY           2823 non-null   object \n"," 21  TERRITORY         1749 non-null   object \n"," 22  CONTACTLASTNAME   2823 non-null   object \n"," 23  CONTACTFIRSTNAME  2823 non-null   object \n"," 24  DEALSIZE          2823 non-null   object \n","dtypes: float64(2), int64(7), object(16)\n","memory usage: 551.5+ KB\n","None\n"]}],"source":["def basic_info(df):\n","    '''checking basic information & shape about the dataframe'''\n","    temp=df.copy(deep=True)\n","    print(\"Shape of the dataset\",df.shape)\n","    print(\"*\"*30)\n","    print(df.info())\n","    \n","basic_info(df)"]},{"cell_type":"markdown","metadata":{"id":"szbU2qr6L8sM"},"source":["### 4.Check the percentage of missing values in each column of the data frame."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bWiVb-9OL8sN","outputId":"0d381eef-2176-49ed-b67a-1e270a0965ad"},"outputs":[{"name":"stdout","output_type":"stream","text":["percentage of missing data of dataframe \n"," ORDERNUMBER          0.000000\n","QUANTITYORDERED      0.000000\n","PRICEEACH            0.000000\n","ORDERLINENUMBER      0.000000\n","SALES                0.000000\n","ORDERDATE            0.000000\n","STATUS               0.000000\n","QTR_ID               0.000000\n","MONTH_ID             0.000000\n","YEAR_ID              0.000000\n","PRODUCTLINE          0.000000\n","MSRP                 0.000000\n","PRODUCTCODE          0.000000\n","CUSTOMERNAME         0.000000\n","PHONE                0.000000\n","ADDRESSLINE1         0.000000\n","ADDRESSLINE2        89.302161\n","CITY                 0.000000\n","STATE               52.639036\n","POSTALCODE           2.692171\n","COUNTRY              0.000000\n","TERRITORY           38.044633\n","CONTACTLASTNAME      0.000000\n","CONTACTFIRSTNAME     0.000000\n","DEALSIZE             0.000000\n","dtype: float64\n"]}],"source":["def check_missing_values(df):\n","    '''Function to check the missing data percentage'''\n","    print(\"percentage of missing data of dataframe \\n\",df.isnull().sum()/len(df)*100)\n","    \n","check_missing_values(df)"]},{"cell_type":"markdown","metadata":{"id":"9tHniECYL8sO"},"source":["- Here we can see the column ADDRESSLINE2 has  89.3% of missing values, STATE has 52.6% of missing values.\n","- POSTALCODE has around 2.69% and TERRITORY has  around 38%."]},{"cell_type":"markdown","metadata":{"id":"UU9oLzTNL8sP"},"source":["- We will drop the ADDRESSLINE2 column and impute other columns with most occured values with the respective column."]},{"cell_type":"markdown","metadata":{"id":"x3qZ-nzYL8sQ"},"source":["### 5. Check if there are any duplicate rows."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VwCjkDKiL8sQ","outputId":"20ebbf51-3f7e-4333-b39a-c80aa02cfcbc"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ORDERNUMBER</th>\n","      <th>QUANTITYORDERED</th>\n","      <th>PRICEEACH</th>\n","      <th>ORDERLINENUMBER</th>\n","      <th>SALES</th>\n","      <th>ORDERDATE</th>\n","      <th>STATUS</th>\n","      <th>QTR_ID</th>\n","      <th>MONTH_ID</th>\n","      <th>YEAR_ID</th>\n","      <th>...</th>\n","      <th>ADDRESSLINE1</th>\n","      <th>ADDRESSLINE2</th>\n","      <th>CITY</th>\n","      <th>STATE</th>\n","      <th>POSTALCODE</th>\n","      <th>COUNTRY</th>\n","      <th>TERRITORY</th>\n","      <th>CONTACTLASTNAME</th>\n","      <th>CONTACTFIRSTNAME</th>\n","      <th>DEALSIZE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","<p>0 rows × 25 columns</p>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: [ORDERNUMBER, QUANTITYORDERED, PRICEEACH, ORDERLINENUMBER, SALES, ORDERDATE, STATUS, QTR_ID, MONTH_ID, YEAR_ID, PRODUCTLINE, MSRP, PRODUCTCODE, CUSTOMERNAME, PHONE, ADDRESSLINE1, ADDRESSLINE2, CITY, STATE, POSTALCODE, COUNTRY, TERRITORY, CONTACTLASTNAME, CONTACTFIRSTNAME, DEALSIZE]\n","Index: []\n","\n","[0 rows x 25 columns]"]},"execution_count":95,"metadata":{},"output_type":"execute_result"}],"source":["def check_duplicate(df):\n","    duplicate=df[df.duplicated()]\n","    return duplicate\n","\n","duplicate=check_duplicate(df)\n","duplicate"]},{"cell_type":"markdown","metadata":{"id":"NgPBf7IuL8sR"},"source":["- As we can see, There is no duplicate columns which is a good thing for us."]},{"cell_type":"markdown","metadata":{"id":"EJAVN2EqL8sS"},"source":["### 6. Write a function that will impute missing values of the columns “STATE”, “POSTALCODE”,“TERRITORY” with its most occurring label.  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uOWtZIshL8sS"},"outputs":[],"source":["def impute_most_occur(df):\n","    df=df.copy(deep=True)\n","    temp_state=df['STATE'].value_counts().index[0]\n","    df['STATE'].fillna(value=temp_state,inplace=True)\n","    temp_postal_code=df['POSTALCODE'].value_counts().index[0]\n","    df['POSTALCODE'].fillna(value=temp_postal_code,inplace=True)\n","    temp_territory=df['TERRITORY'].value_counts().index[0]\n","    df['TERRITORY'].fillna(value=temp_territory,inplace=True)\n","    return df\n","\n","df=impute_most_occur(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YMaivayYL8sT","outputId":"6df0fcbb-3569-4f66-d622-f74ab67c41aa"},"outputs":[{"name":"stdout","output_type":"stream","text":["percentage of missing data of dataframe \n"," ORDERNUMBER          0.000000\n","QUANTITYORDERED      0.000000\n","PRICEEACH            0.000000\n","ORDERLINENUMBER      0.000000\n","SALES                0.000000\n","ORDERDATE            0.000000\n","STATUS               0.000000\n","QTR_ID               0.000000\n","MONTH_ID             0.000000\n","YEAR_ID              0.000000\n","PRODUCTLINE          0.000000\n","MSRP                 0.000000\n","PRODUCTCODE          0.000000\n","CUSTOMERNAME         0.000000\n","PHONE                0.000000\n","ADDRESSLINE1         0.000000\n","ADDRESSLINE2        89.302161\n","CITY                 0.000000\n","STATE                0.000000\n","POSTALCODE           0.000000\n","COUNTRY              0.000000\n","TERRITORY            0.000000\n","CONTACTLASTNAME      0.000000\n","CONTACTFIRSTNAME     0.000000\n","DEALSIZE             0.000000\n","dtype: float64\n","**************************************************\n","Shape of the dataset (2823, 25)\n","******************************\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 2823 entries, 0 to 2822\n","Data columns (total 25 columns):\n"," #   Column            Non-Null Count  Dtype  \n","---  ------            --------------  -----  \n"," 0   ORDERNUMBER       2823 non-null   int64  \n"," 1   QUANTITYORDERED   2823 non-null   int64  \n"," 2   PRICEEACH         2823 non-null   float64\n"," 3   ORDERLINENUMBER   2823 non-null   int64  \n"," 4   SALES             2823 non-null   float64\n"," 5   ORDERDATE         2823 non-null   object \n"," 6   STATUS            2823 non-null   object \n"," 7   QTR_ID            2823 non-null   int64  \n"," 8   MONTH_ID          2823 non-null   int64  \n"," 9   YEAR_ID           2823 non-null   int64  \n"," 10  PRODUCTLINE       2823 non-null   object \n"," 11  MSRP              2823 non-null   int64  \n"," 12  PRODUCTCODE       2823 non-null   object \n"," 13  CUSTOMERNAME      2823 non-null   object \n"," 14  PHONE             2823 non-null   object \n"," 15  ADDRESSLINE1      2823 non-null   object \n"," 16  ADDRESSLINE2      302 non-null    object \n"," 17  CITY              2823 non-null   object \n"," 18  STATE             2823 non-null   object \n"," 19  POSTALCODE        2823 non-null   object \n"," 20  COUNTRY           2823 non-null   object \n"," 21  TERRITORY         2823 non-null   object \n"," 22  CONTACTLASTNAME   2823 non-null   object \n"," 23  CONTACTFIRSTNAME  2823 non-null   object \n"," 24  DEALSIZE          2823 non-null   object \n","dtypes: float64(2), int64(7), object(16)\n","memory usage: 551.5+ KB\n","None\n"]}],"source":["check_missing_values(df)\n","print(\"*\"*50)\n","basic_info(df)"]},{"cell_type":"markdown","metadata":{"id":"5E9L2utWL8sT"},"source":["### 7. Drop “ADDRESSLINE2”,”ORDERDATE”,”PHONE” column."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ImWrWqoRL8sU"},"outputs":[],"source":["df.drop(['ADDRESSLINE2','ORDERDATE','PHONE'],axis=1,inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BVpK6ZoHL8sU","outputId":"70d1f9e8-f7d9-4c24-f369-021a7447f548"},"outputs":[{"name":"stdout","output_type":"stream","text":["percentage of missing data of dataframe \n"," ORDERNUMBER         0.0\n","QUANTITYORDERED     0.0\n","PRICEEACH           0.0\n","ORDERLINENUMBER     0.0\n","SALES               0.0\n","STATUS              0.0\n","QTR_ID              0.0\n","MONTH_ID            0.0\n","YEAR_ID             0.0\n","PRODUCTLINE         0.0\n","MSRP                0.0\n","PRODUCTCODE         0.0\n","CUSTOMERNAME        0.0\n","ADDRESSLINE1        0.0\n","CITY                0.0\n","STATE               0.0\n","POSTALCODE          0.0\n","COUNTRY             0.0\n","TERRITORY           0.0\n","CONTACTLASTNAME     0.0\n","CONTACTFIRSTNAME    0.0\n","DEALSIZE            0.0\n","dtype: float64\n","**************************************************\n","Shape of the dataset (2823, 22)\n","******************************\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 2823 entries, 0 to 2822\n","Data columns (total 22 columns):\n"," #   Column            Non-Null Count  Dtype  \n","---  ------            --------------  -----  \n"," 0   ORDERNUMBER       2823 non-null   int64  \n"," 1   QUANTITYORDERED   2823 non-null   int64  \n"," 2   PRICEEACH         2823 non-null   float64\n"," 3   ORDERLINENUMBER   2823 non-null   int64  \n"," 4   SALES             2823 non-null   float64\n"," 5   STATUS            2823 non-null   object \n"," 6   QTR_ID            2823 non-null   int64  \n"," 7   MONTH_ID          2823 non-null   int64  \n"," 8   YEAR_ID           2823 non-null   int64  \n"," 9   PRODUCTLINE       2823 non-null   object \n"," 10  MSRP              2823 non-null   int64  \n"," 11  PRODUCTCODE       2823 non-null   object \n"," 12  CUSTOMERNAME      2823 non-null   object \n"," 13  ADDRESSLINE1      2823 non-null   object \n"," 14  CITY              2823 non-null   object \n"," 15  STATE             2823 non-null   object \n"," 16  POSTALCODE        2823 non-null   object \n"," 17  COUNTRY           2823 non-null   object \n"," 18  TERRITORY         2823 non-null   object \n"," 19  CONTACTLASTNAME   2823 non-null   object \n"," 20  CONTACTFIRSTNAME  2823 non-null   object \n"," 21  DEALSIZE          2823 non-null   object \n","dtypes: float64(2), int64(7), object(13)\n","memory usage: 485.3+ KB\n","None\n"]}],"source":["check_missing_values(df)\n","print(\"*\"*50)\n","basic_info(df)"]},{"cell_type":"markdown","metadata":{"id":"gLSwZF8WL8sV"},"source":["### 8. Convert the labels of the STATUS column to 0 and 1. For Shipped assign value 1 and for all other labels (i.e. ‘Cancelled’,’ Resolved’,’ On Hold’,’ In Process’, 'Disputed') assign 0. Note we will consider everything apart from Shipped as cancel (i.e. 0).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CsyMc0gRL8sV"},"outputs":[],"source":["df['STATUS']=df['STATUS'].map({'Shipped':1,'Cancelled':0,'Resolved':0,'On Hold':0,'In Process':0,'Disputed':0})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZCIajB9jL8sV","outputId":"5a2af0ed-1dbc-44cc-9968-f7eff8225948"},"outputs":[{"data":{"text/plain":["1    2617\n","0     206\n","Name: STATUS, dtype: int64"]},"execution_count":101,"metadata":{},"output_type":"execute_result"}],"source":["df['STATUS'].value_counts()"]},{"cell_type":"markdown","metadata":{"id":"xmpAl3OZ3GL8"},"source":["- Note: The target class is highly imbalanced."]},{"cell_type":"markdown","metadata":{"id":"Bz2U3ei23GL8"},"source":["### 9. Encode the categorical features using dummy encoding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QKA0irAC3GL8"},"outputs":[],"source":["df = pd.get_dummies(df,drop_first=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c_1Z56uz3GL8","outputId":"2f8cc748-1eb1-4444-c48c-7e322f4cbd0f"},"outputs":[{"data":{"text/plain":["(2823, 634)"]},"execution_count":103,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"markdown","metadata":{"id":"Pwz79Z7t3GL8"},"source":["- Note since we had so many categorical features, after encoding there are huge number of dimensions."]},{"cell_type":"markdown","metadata":{"id":"sXTGIBksL8sW"},"source":["### 10. Separate the target and independent features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mz-g8iawL8sW"},"outputs":[],"source":["X = df.drop('STATUS',axis=1)\n","y = df['STATUS']"]},{"cell_type":"markdown","metadata":{"id":"SM-lcPd43GL8"},"source":["### 11. Split the dataset into two parts (i.e. 80% train and 20% test) using random_state=42. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RpIcvo093GL9","outputId":"c1a36b56-0f11-4ca5-836d-3f32d4200c76"},"outputs":[{"name":"stdout","output_type":"stream","text":["(2258, 633) (565, 633)\n","(2258,) (565,)\n"]}],"source":["X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n","\n","print(X_train.shape,X_test.shape)\n","print(y_train.shape,y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"WKgjYhlcL8sX"},"source":["### 11. Scale the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cizNWrYdL8sY"},"outputs":[],"source":["## Scaling the data using MINMAXSCALAR\n","mm = MinMaxScaler()\n","\n","X_train.iloc[:,:] = mm.fit_transform(X_train.iloc[:,:])\n","X_test.iloc[:,:] = mm.transform(X_test.iloc[:,:])"]},{"cell_type":"markdown","metadata":{"id":"dCPqwLLSL8sc"},"source":["## LDA "]},{"cell_type":"markdown","metadata":{"id":"G0tJG3Fs3GL9"},"source":["### Traning a RandomForest Classfier model before applying LDA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lGrg_YALduWi","outputId":"8aa90d7b-dcc9-48a5-a39d-94060aa1b831"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Accuracy 0.9317980513728964\n","Test Accuracy 0.9079646017699115\n","**************************************************\n","Train confusion matrix \n"," [[   0  154]\n"," [   0 2104]]\n","Test confusion matrix \n"," [[  0  52]\n"," [  0 513]]\n"]}],"source":["rf = RandomForestClassifier(max_depth=3,n_estimators=25)\n","rf.fit(X_train,y_train)\n","y_train_pred = rf.predict(X_train)\n","y_test_pred = rf.predict(X_test)\n","\n","print(\"Train Accuracy\",accuracy_score(y_train,y_train_pred))\n","print(\"Test Accuracy\",accuracy_score(y_test,y_test_pred))\n","print(\"*\"*50)\n","print(\"Train confusion matrix\",'\\n',confusion_matrix(y_train,y_train_pred))\n","print(\"Test confusion matrix\",'\\n',confusion_matrix(y_test,y_test_pred))"]},{"cell_type":"markdown","metadata":{"id":"TD8eznYyL8sd"},"source":["### Training a Linear Discriminant Analysis(LDA) model on the train data. Do fit_transform on the train data and only transform on the test data. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q8zvamhCduWj"},"outputs":[],"source":["lda = LDA(n_components=1)\n","\n","X_train = lda.fit_transform(X_train, y_train)\n","X_test = lda.transform(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I1SCoHeWduWj","outputId":"b5e652f0-cb06-4c31-c15f-4fd6a86887ef"},"outputs":[{"data":{"text/plain":["(array([[ 0.60496511],\n","        [ 0.28984435],\n","        [ 0.6028427 ],\n","        [-0.21719613],\n","        [ 0.27988057]]),\n"," array([[ 1.26394182],\n","        [ 2.52900911],\n","        [ 1.33478261],\n","        [-2.94060547],\n","        [ 0.7395123 ]]))"]},"execution_count":111,"metadata":{},"output_type":"execute_result"}],"source":["X_train[:5],X_test[:5]"]},{"cell_type":"markdown","metadata":{"id":"sh_3AzagL8se"},"source":["### Training a random-forest model on the transformed data  and print the accuracy of train and test data. Take max_depth=3 and n_estimators=25 "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x56LR90VduWj","outputId":"ef97ef76-aab2-477c-d7db-1aab9d50542d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Accuracy 0.9534986713906112\n","Test Accuracy 0.9221238938053097\n","**************************************************\n","Train confusion matrix \n"," [[  93   61]\n"," [  44 2060]]\n","Test confusion matrix \n"," [[ 20  32]\n"," [ 12 501]]\n"]}],"source":["rf=RandomForestClassifier(max_depth=3,n_estimators=25)\n","rf.fit(X_train,y_train)\n","y_train_pred=rf.predict(X_train)\n","y_test_pred=rf.predict(X_test)\n","\n","print(\"Train Accuracy\",accuracy_score(y_train,y_train_pred))\n","print(\"Test Accuracy\",accuracy_score(y_test,y_test_pred))\n","print(\"*\"*50)\n","print(\"Train confusion matrix\",'\\n',confusion_matrix(y_train,y_train_pred))\n","print(\"Test confusion matrix\",'\\n',confusion_matrix(y_test,y_test_pred))"]},{"cell_type":"markdown","metadata":{"id":"2xrTqw67L8se"},"source":["### Conclusion "]},{"cell_type":"markdown","metadata":{"id":"IADYWZYZduWk"},"source":["- As we can see we True negative and False negative points is zero before applying LDA but after applying LDA we are getting some amount of True negative and false negative points.\n","- Due to class imbalance, the majority class has high recall but minority class has poor recall.\n"]},{"cell_type":"markdown","metadata":{"id":"FR3-tBckjtc9"},"source":["### Happy Learning:)"]}],"metadata":{"colab":{"name":"LDA - Hands on.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}